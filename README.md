# 개요
- 정의
    - google: 머신러닝(딥러닝포함)을 사용하여 **텍스트 데이터**를 **처리**하고 **해석**
    - aws : 인간의 언어를 해석, 조작 및 이해하는 능력을 컴퓨터에게 부여한느 기계학습기술

- 데이터
    - 인간의 언어가 담긴 텍스트

- 유형(분야)
    - 자연어 인식(해석)
    - 자연어 생성(요약, 번역, 키워드추출, 답변, ...)
        - NLP
        - LLM 쪽으로 전환
# 워크플로우
# 순환신경망을 이용한 NLP Workflow
## 연구목표
- 목표
    - NLP로 진행가능한 분야
## 데이터 획득
- 말뭉치(코퍼스) 획득
    - 텍스트, STT|TTS, 문서파일(pdf,doc,..), epub,..
    - 수집|획득
        - 모두의 말뭉치
            - https://kli.korean.go.kr/corpus/sign/login.do
        - 국립국어원 한국어 학습자 말뭉치 나눔터
            - https://kcorpus.korean.go.kr/
        - AI 허브
            - https://www.aihub.or.kr/aihubdata/data/list.do?currMenu=115&topMenu=100&&srchDataRealmCode=REALM002
        - 프로젝트 목적상 웹기준 크롤링
            - 교육목적, 비상업화
                - 특정 IP에서 지속적(반복적) request를 발생 -> DDOS로 간주 가능성이 큼 -> IP 차단당함 -> 난수활용 변조->요청시간대를 조작(sleep..)
## 데이터준비, 분석(EDA)
- 전처리
    - 정제 (클린처리)
    - 불용어 처리
## 모델구축
- 전이학습 기반, 허깅페이스에서 획득
    - 2개 구성을 반드시 기반으로 진행
        - 토크나이저
        - 모델
### 토크나이저(통칭) - 토큰화

#### 분절화
- 텍스트 -> 분해 -> **토큰**단위로 나눠야 진행가능
    - 토큰(token) => 사전에 등재되는 단위
        - 값을 하나씩 부여 받게 된다
- 단위
    - 공백(영미권), 단어(특수목적), 형태소(한국어,일본어)등이 분절 단위
    - 형태소
        - NLTK
        - KoNLpy
            - Okt, MeCab, ..
    - 하위 단위 토큰화
        - 바이트 페어 인코딩
        - 워드피스
#### 사전화
- 토큰 단위로 수치를 부여 -> 백터화를 위한 작업
    - 순서대로
    - 의미를 부여해서 진행
    - 수치로 표현되야 -> 딥러닝 학습이 가능함
- 분절화로 나온 토큰을 모아서 사전을 구성
- 토큰에 수치를 어떻게 배치할것인가?
    - 단순한 방법
        - 토큰이 발견 => 수치를 부여
            - 라벨인코더 방식
            - 스페셜토큰 예약하여 추가
                - 문장시작, 문장끝, 첫번째문장, 두번째문장, 패딩,..
    - 언어모델 기반 (백터화에도 등장)
        - ...
        - 카운트 기반 언어 표현
            - 국소 표현 방법(local)
                - Bow, DTM, TF-IDF
            - 분산 표현 방법(distriobutioned)
                - Word2Vec, FastText, Glove

#### 백터화


- 비정형데이터인 텍스트 -> 수치로 표현
- 형태소 기반 토큰화
    - 안녕 오늘 점심 은 ? => [1, 3, 40, 47, 100003]
- 공백 기반 토큰화
    - 안녕 오늘 점심은 ? =>  [2, 5, 36, 80]

- 문장 => 1차원 텐서 => 백터
- 데이터
    - 문장이 여러개

    ```
        [
            [], <- 문장(리뷰 1개,..)
            [], <- 문장
            [],....
        ]
    
    ```

- 단순 사용예시 (시나리오 기반 챗봇, AI 콜센터 가정)
    - 사용자 질문
        - 텍스트
        - STT
    - 토크나이저를 이용하여 백터화
    - 유사한 질문을 검색
        - 단순 반복문 (코드적)
            - **백터 유사도** 비교 진행
            - 거리가 가장 가까운 문장을 검색
        - 엘라스틱서치 등등 문서 검색
        - 백터디비에 데이터를 구축하여 백터검색
            - 백터디비
            - 유사도 검사를 통해서 진행
            - LLM에서 주로 사용
    - 시나리오에 일치하는 질문을 찾았다
        - 답변 응답
        - 단, 질문의 거리가 너무 멀어서 유사한 질문으로 보기 어렵다면 -> 메뉴얼 클릭으로 유도, 다시 질문 유도
    
#### 패딩
- 문장의 길이는 제각각
    - **문장 길이 통일**
- 보정
    - [1,2,3,0,0,0,0]
    - [1,2,3,7,9,0,0]
    - 모든 문장을 같은 크기로 보정
    - 패딩값은 0을 부여 -> 뒤쪽에 보정 혹은 앞쪽으로 보정
    - 스페셜 기호(토큰)를 부여
    - 모델별 상이
#### 임베딩
- 신경망에 데이터를 주입할때 압축해서 주입
- 문장 => 백터를 압축하여 표현
- 카테고리
    - 언어모델
        - 자기 회귀 언어 모델
        - 통계적 언어 모델
        - N-gram 언어 모델
        - 한국어 기반 언어 모델
        - 조건부 확률
    - 워드 임베딩
        - Word2Vec
        - Glove
        - swivel
        - CBOW
        - **Gensim**
        - fastText
        - ...
    - 문장 수준 임베딩
        - Doc2Vec
        - LDA
        - **ELMo**

- 정리
    - 다양한 언어모델등 인코딩 관련 모듈이 존재함
    - 최종 사용하는 모델 기준으로 토크나이저 작업은 결정하는게 적절**일반적 => 모델에 같이 구성된 토크나이저 사용**
        -
### 인공신경망 구축
- 모델 종류
    - 직접 생성
        - 순환인공신경망
            - RNN, LSTM, GRU 형태의 모델구축
        - Seq2Seq
            - 인코더-디코더 방식으로 자연어 분야 적용이 된 초기모델
            - 기계번역
                - 특정 토큰 -> 다음에 등장 토큰을 추론해서 문장을 이어나감
                - 동일언어(답변), 타언어(번역)
        - 성능이 뛰어나진 않지만 신경망의 이해를 위해서는 기본코스

    - 업스트림 모델을 활용하여 전이학습
        - Bert, Bart, GPT, .. 전이학습기반 업스트림 모델을 기반 구축
        - 허깅페이스 기반
            - **트랜스포머** 모듈을 설치하고 진행
        - 분류
            - 어텐션 메커니즘 적용한 모델
            - 인코더-디코더 기반
                - Transformer
                    - BART
                    - T5(Text-To-Text Transfer Transformer)
            - 인코더 기반
                - BERT
                    - ELECTRA
            - 디코더 기반
                - GPT
                    - GPT 2/3/3.5/4/4o
                    - GPT 3부터는 LLM으로 표현
    - LLM
        - openai **GPT4o**
        - Meta **LLaMA 3**
            - R&D
        - standford **Alpaca**
            - R&D
        - google **Gemini**

- 목적
    - 감정분석
        - 긍정/부정
        - 인간의 감정 7가지(심리학과) 분석
            - 필요시 줄여서
    - 키워드 추출
        - 말뭉치 => 핵심 키워드 추출
        - 토픽 모델링
        - 기사 => 정확한 헤드라인 추출
    - 요약
    - 기계번역
## 시스템통합, 모델덤프및 서빙
# 네이버 영화리뷰 데이터를 이용한 감정분석-기본모델사용(Flow중심으로체크)
## 연구목표
- NLP 과정을 처음부터 끝까지 진행
- 데이터 네이버 영화리뷰
- 동작방식
    - 새로운 문장 입력 -> 긍정/부정 응답
    - 이진분류
    - UI
        - 웹기반
            - **gradio**
                - 데모 구성
            - streamlit
                - https://streamlit.io/
                - 순서 파이썬 코드로 웹페이지 구성(프런트기반)
                - 데모구성, 웹구성
            - 웹프로그래밍
                - 백엔드
                    - django <-> spring
                    - flask, fastapi <-> node
                - 프런트
                    - html5, css3, javascript
- 모델
    - 기본 모델 RNN|LSTM 사용
        - 모델 구성에 대한 심도있는 파트는 다음 노트에서 진행
